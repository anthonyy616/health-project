================================================================================
VITAL SIGNS MONITORING SYSTEM - PROJECT CONTEXT
================================================================================
Last Updated: 2026-01-02

================================================================================
PROJECT OVERVIEW
================================================================================
This is a final-year graduation project aimed at optimizing vital sign monitoring 
in hospitals and clinics. The system uses non-invasive, contactless methods where 
possible, combined with a wearable elastic band for continuous monitoring.

Key Vitals Monitored:
  â€¢ Body temperature (requires IR sensor - MLX90614)
  â€¢ Blood pressure (estimated non-invasively)
  â€¢ Eye metrics (pupil dilation via eye tracking)
  â€¢ Heart rate (BPM via remote photoplethysmography - rPPG)
  â€¢ Respiratory rate (breaths per minute via chest movement detection)
  â€¢ Age estimation (via facial ML models)

================================================================================
CORE COMPONENTS
================================================================================

1. CONTACTLESS STATION (Computer Vision)
   - Uses webcam for initial development (laptop built-in webcam)
   - Production: Logitech C920 webcam + MLX90614 IR sensor
   - CV Modules:
     * Face detection & landmarks (MediaPipe)
     * Age estimation (MobileNetV3, trained from scratch + pretrained comparison)
     * Heart rate via rPPG (facial color changes)
     * Respiratory rate (chest movement detection)
     * Pupil dilation (eye tracking with MediaPipe Iris)
     * Temperature (IR sensor integration - hardware dependent)

2. WEARABLE ELASTIC BAND
   - Contains sensors for backup/continuous monitoring
   - Components: ESP32-S3, MAX30102 pulse oximeter, MPU6050 IMU
   - Runs lightweight neural networks (TensorFlow Lite)
   - Data sent via BLE to central unit
   - BLE communication is a MUST-HAVE requirement

3. CENTRAL UNIT
   - Development: Laptop (no Raspberry Pi currently available)
   - Production: Raspberry Pi 4B
   - Processes data, fuses inputs (Kalman filter)
   - Displays results on FastAPI dashboard (HTML frontend)
   - Alerts for anomalies

================================================================================
TECHNICAL SPECIFICATIONS
================================================================================

HARDWARE CONSTRAINTS:
  â€¢ GPU: Intel UHD Graphics (integrated, NO CUDA)
  â€¢ Training: CPU-only (optimized batch sizes, mixed precision disabled)
  â€¢ RAM: Standard laptop specifications
  â€¢ No Raspberry Pi available during development phase

SOFTWARE STACK:
  â€¢ Language: Python 3.11
  â€¢ Computer Vision: OpenCV, MediaPipe
  â€¢ ML Framework: PyTorch (primary), TensorFlow Lite (edge deployment)
  â€¢ Backend: FastAPI (sync endpoints, HTML frontend via Jinja2)
  â€¢ Database: MySQL (local) + Supabase (backup)
  â€¢ Communication: BLE (for wearable band)
  â€¢ Optimization: ONNX Runtime for inference

MODEL TRAINING APPROACH:
  â€¢ Training from scratch (primary approach)
  â€¢ Compare results with pre-trained/transfer learning models
  â€¢ Datasets required: UTKFace (age), UBFC-rPPG (heart rate), VIPL-HR (heart rate)
  â€¢ See docs/datasets.md for download instructions

INFERENCE MODE:
  â€¢ Development: Batch processing acceptable
  â€¢ Presentation/Demo: MUST be real-time inference
  â€¢ Target latency: <10 seconds per scan

================================================================================
DEVELOPMENT PRIORITIES
================================================================================

PHASE 1: CV-ONLY MODULES (No additional hardware required)
  1. âœ… Face detection with MediaPipe (COMPLETE - 478 landmarks, video overlay)
  2. ðŸ”œ Age estimation model (NEXT - download UTKFace, train from scratch)
  3. â³ Heart rate via rPPG
  4. â³ Respiratory rate detection
  5. â³ Pupil detection/eye tracking

PHASE 2: HARDWARE INTEGRATION (When hardware arrives)
  6. â³ Temperature measurement (MLX90614)
  7. â³ Wearable band prototype (ESP32 + sensors)
  8. â³ BLE communication
  9. â³ Sensor fusion (Kalman filter)

PHASE 3: SYSTEM INTEGRATION
  10. â³ FastAPI dashboard
  11. â³ MySQL database integration
  12. â³ Anomaly alerting
  13. â³ Testing with volunteers

================================================================================
CURRENT PROGRESS & NEXT STEPS
================================================================================

COMPLETED:
  âœ… Project structure setup
  âœ… Virtual environment (Python 3.9.1)
  âœ… Dependencies installed (requirements.txt)
  âœ… Camera module working (1280x720 @ 30fps)
  âœ… Face detection module (src/contactless/face_detection/)
  âœ… Video overlay with metrics panel
  âœ… UTKFace dataset downloaded (66,966 images via Kaggle CLI)
  âœ… Raw dataset loader (src/contactless/age_estimation/dataset.py)
  âœ… Memory-efficient preprocessing script (scripts/preprocess_utkface.py)
  âœ… Preprocessed data created (data/processed/utkface/)
      - Train: 46,840 images (70%)
      - Val:   10,035 images (15%)
      - Test:  10,043 images (15%)
      - Image size: 224x224
  âœ… Processed dataset loader (src/contactless/age_estimation/processed_dataset.py)
  âœ… Test suite (tests/test_age_dataset.py) - ALL TESTS PASSING

NEXT STEPS:
  1. ðŸ”œ Build age estimation CNN model (src/contactless/age_estimation/model.py)
  2. Create training script (scripts/train_age.py)
  3. Train from-scratch model on preprocessed UTKFace
  4. Compare with pretrained MobileNetV3-Small
  5. Integrate age estimator into video overlay

RUN COMMANDS:
  Face Detection:    python -m src.main --mode face-detect
  Camera Test:       python -m src.main --mode camera-test
  Preprocess Data:   python scripts/preprocess_utkface.py
  Run Tests:         python tests/test_age_dataset.py


================================================================================
TARGET METRICS & ACCURACY
================================================================================

| Metric              | Target       | Status       |
|---------------------|--------------|--------------|
| Age Estimation      | Â±4 years     | Not Started  |
| Heart Rate (rPPG)   | Â±5 BPM       | Not Started  |
| Temperature         | Â±1Â°C         | Pending HW   |
| Respiratory Rate    | Â±2 BPM       | Not Started  |
| Latency             | <10 seconds  | Not Started  |
| Battery (Band)      | >8 hours     | Pending HW   |

Aggregate accuracy target: 90-95%

================================================================================
TESTING REQUIREMENTS
================================================================================

â€¢ Volunteer Testing: 30 volunteers (REAL requirement, not aspirational)
â€¢ Metrics to measure: accuracy vs ground truth, latency, robustness
â€¢ Lighting conditions: varied (indoor, different skin tones)
â€¢ Data storage: MySQL (local) + Supabase (backup)
â€¢ Privacy: Own database, no HIPAA/GDPR certification required

================================================================================
TIMELINE
================================================================================

Duration: 8-10 weeks (Solo project)
Start Date: January 2026

Week 1-2: Face detection, age estimation model
Week 3-4: rPPG heart rate, respiratory rate
Week 5-6: Pupil detection, model optimization
Week 7-8: Dashboard integration, data fusion
Week 9-10: Volunteer testing, documentation, presentation prep

================================================================================
DATASETS REQUIRED
================================================================================

See docs/datasets.md for detailed download instructions.

| Dataset   | Purpose          | Where to Get                                |
|-----------|------------------|---------------------------------------------|
| UTKFace   | Age estimation   | kaggle.com/datasets/jangedoo/utkface-new    |
| UBFC-rPPG | Heart rate       | sites.google.com/view/yaboromance/ubfc-rppg |
| VIPL-HR   | Heart rate (adv) | vipl.ict.ac.cn (request access)             |

================================================================================
MEDICAL REFERENCES
================================================================================

â€¢ Non-contact IR thermography: IEEE TBME (2021) on fever screening
â€¢ rPPG: Wang et al., IEEE TBME (2017)
â€¢ Respiration via IMU: AL-Rawi et al. (2020)
â€¢ Pupil detection: Iskander et al. (2019)
â€¢ Age estimation: Rothe et al., DEX model (IMDB-WIKI)
â€¢ Wearable systems: Pantelopoulos & Bourbakis, Sensors (2010)

================================================================================
DATABASE CONFIGURATION
================================================================================

Database: health_record_project (MySQL)
Admin User: vitals_admin
Environment: .env file (copy from .env.example)

Connection Module: src/db_connect/
  â€¢ connection.py - MySQL connection manager with pooling
  â€¢ queries.py - Pre-built queries for patients, readings, alerts
  â€¢ statistics.py - ML statistics and accuracy analysis

Tables:
  â€¢ patients - Patient demographics
  â€¢ health_record_project - Vital readings (renamed from vital_readings)
  â€¢ alerts - Anomaly alerts with severity levels
  â€¢ volunteers - 30-volunteer testing registry
  â€¢ test_sessions - Ground truth data for accuracy testing
  â€¢ model_performance - From-scratch vs pretrained comparison

Setup Steps:
  1. Run docs/create_admin_user.sql in MySQL Workbench
  2. Run docs/database_schema.sql to create tables
  3. Copy .env.example to .env and set DB_PASSWORD
  4. Test: python -m src.db_connect.connection

================================================================================
ML STATISTICS FEATURES
================================================================================

Module: src/db_connect/statistics.py

Features:
  â€¢ get_summary() - Aggregate statistics from all readings
  â€¢ calculate_accuracy() - MAE, RMSE vs ground truth
  â€¢ get_model_comparison() - From-scratch vs pretrained results
  â€¢ volunteer_progress() - Track 30-volunteer requirement
  â€¢ get_readings_by_condition() - Analyze by lighting/skin tone/motion
  â€¢ plot_error_distribution() - Visualize prediction errors
  â€¢ print_report() - Generate formatted statistics report

Usage:
  from src.db_connect.statistics import MLStatistics
  stats = MLStatistics()
  stats.print_report()

================================================================================
DEVELOPMENT ENVIRONMENT
================================================================================

Python Version: 3.9.1 (REQUIRED - mediapipe compatibility)
Virtual Environment: .venv (must be activated before running)

Activation Commands:
  Windows: .\.venv\Scripts\activate
  Linux/Mac: source .venv/bin/activate

Running the Camera Test:
  python -m src.main --mode camera-test
  # Or with explicit venv python:
  .\.venv\Scripts\python.exe -m src.main --mode camera-test

Running Modes:
  --mode camera-test    # Test webcam (press 'q' to quit)
  --mode face-detect    # Face detection with landmarks
  --mode age            # Age estimation
  --mode heart-rate     # rPPG heart rate detection
  --mode dashboard      # Start FastAPI dashboard
  --mode all            # Full vital signs monitoring

================================================================================
VIDEO OVERLAY FEATURES
================================================================================

The camera/video output must display real-time metrics overlay:

Display Elements:
  â€¢ Face bounding box (green rectangle)
  â€¢ Facial landmarks (468 points visualization)
  â€¢ Age estimation (top-left: "Age: 25 Â±4 years")
  â€¢ Heart rate (top-left: "HR: 72 BPM")
  â€¢ Respiratory rate (top-left: "Resp: 16 BPM")
  â€¢ Pupil dilation (top-left: "Pupil: 4.5mm")
  â€¢ Confidence bars for each metric
  â€¢ FPS counter (bottom-right)
  â€¢ Processing latency (bottom-right)

Overlay Styling:
  â€¢ Semi-transparent background for text readability
  â€¢ Color-coded alerts (green=normal, yellow=warning, red=critical)
  â€¢ Smooth transitions for metric updates
  â€¢ Status indicators for each module

================================================================================
NOTES FOR AI ASSISTANT
================================================================================

â€¢ Use this file as the primary context window for all code generation
â€¢ Assume good intent; focus on feasibility for student project
â€¢ Prioritize CV-only modules first (no hardware dependencies)
â€¢ CPU-only training - optimize batch sizes accordingly
â€¢ FastAPI backend with HTML frontend (not React/Vue)
â€¢ BLE for wearable is a MUST-HAVE, not optional
â€¢ Real-time inference required for final presentation
â€¢ All models trained from scratch, then compared to pre-trained
â€¢ Python 3.9.1 is REQUIRED for mediapipe compatibility
â€¢ Video overlay with metrics is a core feature

================================================================================

